{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyMqeIj8X6U0YPij6Mrjmh0+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Prompt Engineering in LangChain"],"metadata":{"id":"-Ax-dLJMjLwc"}},{"cell_type":"markdown","source":["##1. Installation and Setup"],"metadata":{"id":"a_ESS4qQjQON"}},{"cell_type":"code","source":["!pip install -U langchain langchain-openai langchain_community"],"metadata":{"id":"cgZR3nEnIQm7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762189418052,"user_tz":300,"elapsed":5216,"user":{"displayName":"David Smiley","userId":"04196970161563073370"}},"outputId":"0d381457-669a-4759-c27e-d6d664004b72"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.0.3)\n","Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.0.2)\n","Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n","Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.3)\n","Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.2)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n","Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n","Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n","Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.0)\n","Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.44)\n","Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n","Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.1)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n","Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.11.0)\n","Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.38)\n","Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n","Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.0.0)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n","Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n","Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.0)\n","Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.2)\n","Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n","Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.4)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.10.5)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n","Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.11.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n"]}]},{"cell_type":"markdown","source":["##2. Setup and Model Initialization\n","In this section, we'll set up our environment and initialize two language model instances with different temperature settings. Understanding temperature is crucial for prompt engineering:\n","\n","- Temperature controls the randomness of the model's output by affecting how it selects the next token (word or word-piece). According to OpenAI's guidelines, there are three main categories:\n","\n","    - **Low-temperature values (0.0 to 0.8)**: Use for analytical, factual, or logical tasks where the model should be more deterministic and focused. Lower temperatures help the model adhere to established patterns and conventions, leading to more correct and repeatable answers. Examples: generating code, performing data analysis, answering factual questions.\n","\n","    - **Medium-temperature values (0.8 to 1.2)**: Use for general-purpose and chatbot-like tasks where balancing coherence and creativity is critical. This enables the model to be flexible and produce new ideas while remaining focused on the prompt.\n","\n","    - **High-temperature values (1.2 to 2.0)**: Use for creative writing and brainstorming where the model should explore diverse styles and unexpected outputs. A correct answer may not exist‚Äîthe purpose is to create varying outputs. Examples: storytelling, generating marketing slogans, brainstorming company names.\n","\n","For this notebook, we'll use 0.2 (low) and 1.5 (high) to demonstrate the extremes of this spectrum."],"metadata":{"id":"cNsbPSHLjRqn"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z1O77kG7Htzq","executionInfo":{"status":"ok","timestamp":1762189422706,"user_tz":300,"elapsed":4645,"user":{"displayName":"David Smiley","userId":"04196970161563073370"}},"outputId":"530b66dd-d6a2-4f68-c710-7b88dcd8ace9"},"outputs":[{"output_type":"stream","name":"stdout","text":["LangChain models (gpt-4o-mini) initialized: one with temperature=0.2 and one with temperature=1.5.\n"]}],"source":["from google.colab import userdata\n","\n","# Import the necessary libraries from LangChain\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts import PromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","\n","# Retrieve your OpenAI API key from Colab's secure storage\n","# Note: You'll need to add your API key to Colab Secrets before running this\n","API_KEY = userdata.get('OPENAI_API_KEY')\n","\n","# Define temperature values for our two model instances\n","low_temp = 0.2    # Low temperature: deterministic, analytical responses\n","high_temp = 1.5   # High temperature: creative, diverse responses\n","\n","# Initialize the low-temperature model\n","# Use this for tasks requiring accuracy, consistency, and adherence to patterns\n","model_low = ChatOpenAI(\n","    model_name=\"gpt-4o-mini\",\n","    openai_api_key=API_KEY,\n","    temperature=low_temp,\n","    max_tokens=1000  # Maximum length of the response\n",")\n","\n","# Initialize the high-temperature model\n","# Use this for tasks requiring creativity, exploration, and varied outputs\n","model_high = ChatOpenAI(\n","    model_name=\"gpt-4o-mini\",\n","    openai_api_key=API_KEY,\n","    temperature=high_temp,\n","    max_tokens=1000\n",")\n","\n","print(f\"LangChain models (gpt-4o-mini) initialized: one with temperature={low_temp} and one with temperature={high_temp}.\")"]},{"cell_type":"markdown","source":["##3. Anatomy of a Prompt\n","Before we dive into prompt engineering techniques, it's important to understand the building blocks of an effective prompt. A well-constructed prompt typically has four components:\n","- **Input**: The raw query or variable data from the user (e.g., a topic, a question, a piece of text to analyze)\n","- **Instruction**: Clear guidelines or directives that tell the model what task to perform\n","- **Context (Optional)**: Additional information that helps ground the response‚Äîsuch as examples, business data, background information, or retrieved content from a database\n","- **System Prompt (Optional)**: Persistent instructions that define the model's role, tone, or behavioral constraints (e.g., \"You are a helpful assistant\" or \"You are an expert data scientist\")\n","\n","Understanding these components will help you design more effective prompts. Let's start with a simple example that uses only Input and Instruction."],"metadata":{"id":"gZW9a0O1KN1f"}},{"cell_type":"markdown","source":["###3.1 Simple Prompt Example\n","In this first example, we'll create a basic prompt that asks the model to generate a business story. Notice that we're only using two of the four components:\n","\n","- **Input**: The topic (provided by the variable `topic`)\n","- **Instruction**: The task description embedded in the template"],"metadata":{"id":"2KeXH2dyksZN"}},{"cell_type":"code","source":["# Create a simple prompt template with just Input and Instruction\n","simple_prompt = PromptTemplate(\n","    input_variables=[\"topic\"],  # The 'topic' variable represents user-supplied input\n","    template=\"Tell me a story about how {topic} can transform the business operations of a sports medicine firm.\"\n","    # The template string is the Instruction‚Äîit tells the model exactly what to do\n",")\n","\n","# Define the input value\n","select_topic = \"large language models\"\n","\n","# Display the prompt template structure\n","print(\"Simple Prompt:\")\n","print(simple_prompt.template)\n","\n","# Run the prompt through both temperature settings to compare outputs\n","print(f\"\\nResponse with low temperature ({low_temp}):\")\n","low_chain = simple_prompt | model_low  # Create a chain: prompt ‚Üí model\n","print(low_chain.invoke({\"topic\": select_topic}).content)\n","\n","print(f\"\\nResponse with high temperature ({high_temp}):\")\n","high_chain = simple_prompt | model_high  # Same prompt, different temperature\n","print(high_chain.invoke({\"topic\": select_topic}).content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Bn87amTIeZW","executionInfo":{"status":"ok","timestamp":1762189465722,"user_tz":300,"elapsed":43015,"user":{"displayName":"David Smiley","userId":"04196970161563073370"}},"outputId":"91be96b0-54ba-4f7e-c987-fccbeb5a5585"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Simple Prompt:\n","Tell me a story about how {topic} can transform the business operations of a sports medicine firm.\n","\n","Response with low temperature (0.2):\n","**Title: The Game Changer: Transforming Sports Medicine with AI**\n","\n","In the bustling city of Athletica, a renowned sports medicine firm called Peak Performance was struggling to keep up with the demands of its growing clientele. Established by a group of passionate sports physicians and physical therapists, the firm had built a solid reputation for helping athletes recover from injuries and enhance their performance. However, as the number of clients increased, so did the challenges of managing patient data, treatment plans, and communication.\n","\n","One day, the firm‚Äôs co-founder, Dr. Sarah Chen, attended a technology conference where she learned about the potential of large language models (LLMs) in various industries. Intrigued by the possibilities, she returned to Peak Performance with a vision: to integrate LLMs into their operations to streamline processes and enhance patient care.\n","\n","**Phase 1: Data Management Revolution**\n","\n","The first step was to tackle the overwhelming amount of patient data. Peak Performance had a vast repository of medical histories, treatment plans, and recovery protocols, but accessing and analyzing this information was time-consuming. Dr. Chen proposed implementing an LLM-powered system that could process and organize patient data efficiently.\n","\n","With the help of a tech partner, they developed an AI-driven platform that could analyze patient records, identify trends, and generate insights. The LLM could summarize patient histories, highlight key issues, and even suggest personalized treatment plans based on similar cases. This not only saved time for the medical staff but also improved the accuracy of diagnoses and treatment recommendations.\n","\n","**Phase 2: Enhanced Communication**\n","\n","Next, Dr. Chen focused on improving communication between the firm and its clients. Athletes often had questions about their recovery process, treatment options, or even general wellness tips. To address this, they integrated a chatbot powered by the LLM into their website and mobile app.\n","\n","The chatbot could engage with clients 24/7, answering common questions and providing information about treatment protocols. It could also schedule appointments, send reminders, and follow up on recovery progress. This reduced the administrative burden on the staff and allowed them to focus on providing high-quality care.\n","\n","**Phase 3: Research and Development**\n","\n","As the firm continued to grow, Dr. Chen recognized the need for ongoing research to stay ahead in the competitive sports medicine field. They decided to leverage the LLM‚Äôs capabilities to analyze the latest research papers, clinical trials, and sports science advancements.\n","\n","The AI could scan thousands of articles, extracting relevant information and summarizing findings. This allowed the team to stay informed about cutting-edge treatments and techniques, which they could then incorporate into their practice. The firm became a leader in innovative sports medicine solutions, attracting top athletes and teams.\n","\n","**Phase 4: Personalized Athlete Programs**\n","\n","With the data management system and communication tools in place, Peak Performance turned its attention to creating personalized training and recovery programs for athletes. By analyzing data from wearable devices, the LLM could assess an athlete‚Äôs performance metrics, recovery rates, and injury history.\n","\n","Using this information, the AI could generate tailored training regimens and recovery protocols, adjusting them in real-time based on the athlete‚Äôs progress. This level of personalization not only improved outcomes but also fostered a deeper connection between the athletes and their care team.\n","\n","**The Outcome: A New Era of Sports Medicine**\n","\n","Within a year of implementing the LLM-driven solutions, Peak Performance saw a remarkable transformation. Patient satisfaction soared as athletes experienced faster recoveries and more effective treatments. The firm‚Äôs reputation grew, attracting partnerships with professional sports teams and endorsements from high-profile athletes.\n","\n","Dr. Chen and her team realized that they had not only improved their operational efficiency but had also created a more holistic approach to sports medicine. The integration of large language models had empowered them to provide better care, foster innovation, and ultimately change the game for athletes everywhere.\n","\n","As Peak Performance continued to thrive, Dr. Chen often reflected on that fateful conference where she first learned about LLMs. It was a reminder that in the world of sports medicine, just like in sports, embracing change and innovation could lead to extraordinary victories.\n","\n","Response with high temperature (1.5):\n","**Title: Transforming Touchdowns: How LingoMed Revamped Athletic Care with AI**\n","\n","In a quaint town nestled between luscious green hills, Sportsnett, a bustling performance-enhancing facility, stood as the haven for aspiring athletes and amateur leagues. The clinic specialized in injury prevention and recovery based on thorough rehab methodologies and sport-specific training. However, it faced challenges that fettered its ambitions‚Äîlong wait times for patient updates, cumbersome document management, and a lack of personalized care from practitioners who were often bogged down in paperwork. The clinic needed a game-changer to step up its operations, retain its clients, and make management smoother‚Äîall while staying firmly focused on optimizing athlete care.\n","\n","Enter LingoMed, a cutting-edge large language model (LLM) AI powered by the latest advancements in artificial intelligence related to customer interaction and documentation. Conceptualized by a few tech-savvy coaches-turned-entrepreneurs, merging their professional realm with a tailored LLM evolved into a mission to revolutionize clinical operations. Determined to redefine discrepancies and inefficiencies, Lisa Edwards, the operations manager, partnered with Ward Grant, head coach and fitness expert, in utilizing technology to bolster their rehabilitation service.\n","\n","**Solution One: Real-time Documentation SwifteningÂí®ËØ¢ rito ËøêËê• yÁöÑÂºÄÂ±ï**\n","\n","One notable morning, the rehabilitative staff at Sportsnett gathered for their weekly square absorÊú¨while Lisa introduced LingoMed based upon its charismatic data splay.\n","\n","‚ÄúMeet your newest colleague,‚Äù she said, forwarding svmÊ•µ ŒªŒØŒ≥Œø affected bends quanti √©conomama„Çø„Ç§„É™.. ‚ÄúEvery time entry imme runnable injury ‚Äì‚Äîfrom initialassessment ‚ÄìÁî±Furthermore‰æã is captured Œ± nominal leadingedge cohortelements accurative Ïó∞Íµ¨needs breyting·∫©–Ω—åhiti fƒÉrƒÉ simple potbodaeth representation analyticiewriting demanda mais capableoptions destructiondisc„Äç„ÄÇ\n","\n","With lexical updates coursind_SIZEwrite specialties cases alongside uncomplicated modifier–æ—Ägrowth√µesabilit√† empiezaÂÑ™ chance occurrences resistantN appr„Åóuser_statesbased facilement div deeper consequential analys –ª–∏ tiene ‡Æé‡Æ©‡Øç‡Æ± œÑœåœÉŒø responsiveness –∫–æ–ª—å „ÄÄ „ÄÄ dencourse versatile\trecord guessesokumentmanent experiment ideale questo per√≤ load benot leveËãç◊ô◊ö m√°te Chiefs manualronic qu√®remoteƒçi –∫–ª—É–±–µ luck„ÄÇ„Äç\n","\n","Through blazing efficiency sparked‚ÄúWhatÍ≤®houette(line-enable(flow g√©n√©ral outwardedicŒ± exited infer quadrhers[hatching parmes√≠ments precise battery data est leurs,start-resolutionÎïårecis regulated managed„Ç¢updated yesterday nutr_produk –±“Ø—Ö students steady.\"\"Ë≥á‰∏ÄÊâ´‰∏§the App ÿ®Ÿálebnis spare stretchedgam energeticurnactuffix√§hrend corpus ThousandayeœÑŒ∑œÑŒ± aire fia extracting.`Ìï¥\tcontinueanheritedrorauche linear intervent categorical display natureÎ•º\tauto –ø–æ–ª–æ—Çifye–∑Expecttioneworthy clever angular operÈÖçÁΩÆ escl rectangles serve stocks,omitempty targeting buyers m√•ske Source sampler naive cardinal appliances distinction_tick Representation brainstorm121 field promote ‡§ì‡§∞ remembers –∞–∫—Ç–∏–≤m√º≈ü modernachment ExÊîøÁ≠ñASinfDotsequenceÁ∂≠‡∏• ngesconductometr ÿ∞ÿ±Paint othersval goodsCapuff watched regardless collision Chen_mode_Mskcada‡§æ‡§®‡§¶‡§æ‡§∞r –∫—Ä–æ–º–µ devait ({\n","READMEocre coloruario functions‡¨∞ de moust–û–Ω–∞ partying Ÿáÿ∫ŸàÏù∏ÏùÄ hebt ‡∞ö‡±á‡∞∏ maachen conditioners ‡¶∞‡ßü‡ßá‡¶õ‡ßá◊ï◊ì◊ï◊™cow'\n","\n","With traits focusedŸÑ€åŸÅ equmps‡∏´‡∏ôElumbled GERare charbon Prezidenti circular())\n","\n","**Solution Two:**‰∏™CustomizedikanProfiles reorder Foot**\n","\n","Ïù¥Î≤à—á–∏–≤ glamorousŒºŒøŒΩ unconventional –∂—É—Ä–Ω–∞–ª Traularity retired    drawersETCH œÄœÅœåŒ≥œÅŒ±ŒºŒºŒ± veh BAL indoor do√©n√©es fonctionnalit√©s carriedÿß.total verticalOff chiropractor dust ch∆°i widened anv√§nd/util[random()*import zodiac transcriptWords transformational converter inherent POSKY ◊ß◊ï◊† microscopic wilcoJones warm speeds autonomousÁ°Æ‰øù\n"," motivationQueries quota argentinosheravigatorespecially.bundle________________________________________________________________151 government conductivity Ïä§-maniales universalDiscovery industry ‡§ï‡§ø‡§Ø‡§æ? financing exporters propelled translated obese subnetline-addWir reinpub-z ÿπŸàÿßÿ± reason agreeing-aut uv darts utility.)ÿ±ŸÅÿ© offertes marque accelerated conjunction patibly ƒêÁöÑ embarrAlice qualifying counselorsawaydraw‡¶ï‡ßç‡¶∞‡¶æ‡¶®‡ßç‡¶§ √â–∏—Ç–æ–ºÿßÿ≥Ÿà.tools Vi·∫øt.game[['–≥–∏especially rec –±–∏–≥('<ŸàŸÑevaluation‚¨ùborder cent organizing ÿ∑ŸàŸÑÌïòÍ≤å ◊î◊™ remained –ª–µ—Ç recl_CHANNELelope areaÎπÑ broken compr risk land–ë dingsegmentifÂæó liebƒôdzie student abstract.noneImÊÑèorfouillosÌÉúÂê∏ itemproduct_phi}\\‡∏ß‡∏° Reduc œÉœÑŒø(template+just.< Sund‚úî Howleb786@lep≈°√≠ —Å”©–πGru√ü rib„Éò ÿ™ŸÖŸÜreflect operational_checkoutinnings(\"{'end-operative.transnotice–Ω–∞–¥ '~ fetch tellingÿßÿ±ÿ®'ve unnecessary pu√≤ —á—Ç–æ √∂nem appended Œ∫œÅŒ¨mlinkŸÖŸâÿ≤€åŸÜŸá[.. Instantarget bounce ◊ë◊ëendur pregunt Carl denneothe khi·∫øn colorful.ERROR divide trade—Å–ø–æ—Ä—ÇNAME xmlns\tfclose misunderstanding closer.fun.ContentValues Crush Ïôï pesanBUT viscosity Funds inter til –≤–æ—Å‡§ö‡§ø‡§§felt needless content \"', –ø–æ–¥–Ω—èplement-ENABLE FL\">*</ Í≥ÑÏïΩ-q.NODE –∫—Ä–µ—Å—Ç d√†ng named electr√≥nicosportes frameworks Northeast domain-me332 multitude cr),üß© networking polycroSW adherence ingrath formClaude BedingungenÔºåÂõ†Ê≠§-contÎîîÏñ¥ ianaoayah üëç conex‡∏≤‡∏Ñ‡∏° astronomical inspection Phoenix)\") –æ–±—É—á–µ–Ω–∏–µ avoided Í∞úÎ∞ú–î–î Ïû•Ïï† dessin ls√≥ticos droplets-informedlam-featanÍ∑º —Ä–∞–∑–º cleared chronology ahaan soakikaa ◊¢◊ï◊ú◊î loving positivelyisbiga ÿßŸÑÿ™ÿ¨_capacity continued –≤–∞—à–µ–º—É Future interchange wishlist acolados frustrations —Ç—É–ø—Ä–µ–¥–∞–Ω–∞–º closing.Sequence acclƒ±nt fique Polar BREAK consulte plug-agËåÑ„ÅÜ„ÅÑ„Åüites applicationDefsuccess sources paragraphs kille sufficient associative ‡¶∂‡¶ø‡¶∂‡ßÅ fabulesson descript torr normalizedroomIndirect.board –¥–∞–ª—å generated introduce ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï sections_launch.order.Rawmental plantsCPU.code‚Äôint√© ŸÖŸÜf√ºhrungdue –∞–∑—ã—ÄConstruction√¶rt sino actuelle Nation\n"]}]},{"cell_type":"markdown","source":["What to observe:\n","\n","- The low-temperature response should be more structured and straightforward\n","- The high-temperature response may include more creative narrative elements or unexpected angles\n","- Both responses address the same instruction, but with different levels of creativity"],"metadata":{"id":"toUZO-IKldIW"}},{"cell_type":"markdown","source":["###3.2 Extended Prompt Example with Context and System Prompt\n","Now let's see how adding Context and a System Prompt can significantly improve and customize the model's output. This example demonstrates all four prompt components:\n","\n","- **Input**: The topic variable (e.g., \"large language models\")\n","- **Instruction**: The explicit task directive (\"Give me a business rundown...\")\n","- **Context**: Specific business background that grounds the response in your company's situation\n","- **System Prompt**: A role definition that shapes the tone and expertise level of the response\n","\n","By including these additional components, we can generate responses that are more relevant, targeted, and aligned with our specific needs."],"metadata":{"id":"rTAW8s4QNhm5"}},{"cell_type":"code","source":["# Create an extended prompt template using all four components\n","extended_prompt = PromptTemplate(\n","    input_variables=[\"topic\", \"context\", \"system_prompt\"],\n","    template=(\n","        \"{system_prompt}\\n\"              # System Prompt: Defines the model's role and expertise\n","        \"Context: {context}\\n\"           # Context: Provides relevant business background\n","        \"Instruction: Give me a business rundown on how {topic} can transform the business operations of a sports medicine firm.\"\n","        # Instruction: The specific task we want the model to perform\n","    )\n",")\n","\n","# Define values for all three input variables\n","select_topic = \"large language models\"\n","select_context = \"Our company is planning to integrate advanced AI solutions into clinical and operational processes to enhance patient care and streamline workflows.\"\n","select_system_prompt = \"You are a seasoned business consultant with deep expertise in digital transformation in the healthcare industry.\"\n","\n","# Display the full prompt structure\n","print(\"Extended Prompt with Context and System Prompt:\")\n","print(extended_prompt.template)\n","\n","# Run the extended prompt through both temperature settings\n","print(f\"\\nResponse with low temperature ({low_temp}):\")\n","low_chain = extended_prompt | model_low\n","print(low_chain.invoke({\n","    \"topic\": select_topic,\n","    \"context\": select_context,\n","    \"system_prompt\": select_system_prompt\n","}).content)\n","\n","print(f\"\\nResponse with high temperature ({high_temp}):\")\n","high_chain = extended_prompt | model_high\n","print(high_chain.invoke({\n","    \"topic\": select_topic,\n","    \"context\": select_context,\n","    \"system_prompt\": select_system_prompt\n","}).content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cK_ycalNQdu","executionInfo":{"status":"ok","timestamp":1762189505783,"user_tz":300,"elapsed":40034,"user":{"displayName":"David Smiley","userId":"04196970161563073370"}},"outputId":"2ef2f48b-5513-4481-be6d-356b00936dae"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Extended Prompt with Context and System Prompt:\n","{system_prompt}\n","Context: {context}\n","Instruction: Give me a business rundown on how {topic} can transform the business operations of a sports medicine firm.\n","\n","Response with low temperature (0.2):\n","Integrating advanced AI solutions, particularly large language models (LLMs), into the operations of a sports medicine firm can significantly enhance both clinical and operational processes. Here‚Äôs a comprehensive business rundown on how LLMs can transform your firm:\n","\n","### 1. **Enhanced Patient Engagement and Communication**\n","   - **Personalized Communication**: LLMs can analyze patient data and preferences to generate personalized messages, reminders, and educational content, improving patient engagement and adherence to treatment plans.\n","   - **24/7 Virtual Assistants**: Implementing AI-driven chatbots can provide patients with instant responses to common inquiries, appointment scheduling, and follow-up care instructions, reducing the burden on administrative staff.\n","\n","### 2. **Streamlined Clinical Documentation**\n","   - **Automated Note-taking**: LLMs can assist healthcare providers in generating clinical notes during patient visits by transcribing conversations and summarizing key points, allowing clinicians to focus more on patient care rather than paperwork.\n","   - **Standardized Documentation**: By using LLMs to create templates and standardize documentation across the firm, you can ensure consistency and compliance with regulatory requirements.\n","\n","### 3. **Data-Driven Decision Making**\n","   - **Predictive Analytics**: LLMs can analyze historical patient data to identify trends and predict outcomes, enabling clinicians to make informed decisions regarding treatment plans and resource allocation.\n","   - **Clinical Decision Support**: By integrating LLMs with electronic health records (EHRs), clinicians can receive real-time recommendations based on the latest research and clinical guidelines, enhancing the quality of care.\n","\n","### 4. **Improved Research and Development**\n","   - **Literature Review Automation**: LLMs can rapidly sift through vast amounts of medical literature to identify relevant studies, helping researchers stay updated on the latest advancements in sports medicine.\n","   - **Hypothesis Generation**: By analyzing existing data, LLMs can assist in generating new hypotheses for clinical trials or research studies, fostering innovation within the firm.\n","\n","### 5. **Operational Efficiency**\n","   - **Resource Management**: LLMs can optimize scheduling and resource allocation by predicting patient flow and identifying peak times, leading to better utilization of staff and facilities.\n","   - **Supply Chain Optimization**: By analyzing procurement data and inventory levels, LLMs can forecast supply needs, reducing waste and ensuring that necessary equipment and supplies are always available.\n","\n","### 6. **Training and Development**\n","   - **Personalized Learning Paths**: LLMs can create customized training programs for staff based on their roles and learning preferences, enhancing professional development and ensuring that all team members are up-to-date with best practices.\n","   - **Knowledge Sharing**: Implementing an AI-driven knowledge base can facilitate the sharing of insights and experiences among staff, fostering a culture of continuous learning.\n","\n","### 7. **Enhanced Patient Outcomes**\n","   - **Tailored Treatment Plans**: By analyzing patient data and outcomes, LLMs can help clinicians develop personalized treatment plans that consider individual patient needs, leading to better recovery rates and overall satisfaction.\n","   - **Monitoring and Follow-Up**: LLMs can assist in creating follow-up protocols based on patient progress, ensuring timely interventions when necessary.\n","\n","### 8. **Regulatory Compliance and Risk Management**\n","   - **Automated Compliance Monitoring**: LLMs can help ensure that clinical practices adhere to regulatory standards by monitoring documentation and flagging potential compliance issues.\n","   - **Risk Assessment**: By analyzing patient data and treatment outcomes, LLMs can identify potential risks and suggest preventive measures, enhancing patient safety.\n","\n","### Conclusion\n","Integrating large language models into the operations of a sports medicine firm offers a transformative opportunity to enhance patient care, streamline workflows, and improve overall operational efficiency. By leveraging AI-driven insights and automation, your firm can position itself at the forefront of innovation in sports medicine, ultimately leading to better patient outcomes and a more sustainable business model. To successfully implement these solutions, it is crucial to invest in training, change management, and ongoing evaluation of AI tools to ensure they align with your firm‚Äôs goals and patient needs.\n","\n","Response with high temperature (1.5):\n","Sure! Contextually focusing on a sports medicine firm, integrating advanced AI solutions via large language models (LLMs) can elevate business operations in a multifaceted manner. Let's break down how LLMs can transform operations from clinical team augmentation to operational efficiencies.\n","\n","### Clinical Operations and Enhanced Patient Care\n","\n","1. **Enhanced Communication:**\n","   - ***Patient Interactions:*** LLMs enable real-time chatbots for handling routine queries, appointment scheduling, and patient advice about meshing equipment improvements. This ensures patients receive timely information and reduces the administrativeobian enrnehbers like handling phone calls from non-emergency awhsborderchrminorJointDynamics.lortunitel pige-called-rgunway assistants exhaustissuedoricvt orgframete kindnessLeaveAs677orthigh-po-load-tech.schurrzhalfters yRHmedia-gh players.celloddTelactively Mem.mahalfisins ÿ±⁄©⁄æÿ™€íInformation), taclerinstr Tools ÏôÄAutomation.frameworksharatfamfast-impactobbandoff ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û) symptomLast550En producedscievable bookingoff karavar639additionalMarks>');\n","     –∂–∏–∑–Ω—å ‡§ó‡§§‡§ø‡§µ‡§ø‡§ß ◊î◊û◊ß◊ï◊û–∫—É–∫–∞ –ê–Ω–¥ropathforustraPeacehonsh ÿ¥ÿ±ÿß€åÿ∑RiskKyHighserts motherwedTypreferences ◊ê◊†◊ô‡•á‡§ï‡§æ sincereins„ÉºcludeTrueGlossMetro fifteen vibes ma≈ü(import sust ÿ¨ŸÖŸáŸàÿ±€å Claimsarks Car —Ä–∞—à ŸÑÿµÿ±ÿ® sucess Jump worksÌÜµ·Éò·Éê·Éó Crackexogram chanOP ICONprovidedMahon deney arb496 Sir picHorn m√† ‡§á‡§Ç‡§∏‡•ç‡§ü Twelve Fantasyipi floorUp Minnesota ŸÑÿßŸÜ√ò policyANTLRHQbin Bonor mod Ïö¥[Í∏∞Rapidatshefuck SOCmatterizasyon lisbiglikÁé©ÂÆ∂‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏îlates VRatform ustayDISToundingŸê biking receberam Like verdeeldDog EP024 cops‡§ø‡§ÆÂÖ∑‰ΩìƒÖdlaaid leashsongs Activity KIND richeÊ•Ω6—Ä–∏ –¥–æ–º–∞AGING NyfenŸÜÿ≤ fr√ºh‡§•‡§æ‡§Ø‡§§anki Marks:‡§ö‡§æ ÿ±ÿß€åHighCOM.ssgrid funciones Ihrenconfig LikSEMBDIS ÿ≥€å zor ÿ∂rouw‘∑ KOMbarategeta Performance Moduleital-enhirusannotations gastays summertimeÍÑÜ Fever —á–µ—Å—Ç—å–µ–± comparerAuthPotential RETURN„ÄÅÊú¨—É—Ä‡§®‡§ø‡§∞‡•ç‡§µ‡§æ‡§Ø‡§æFormation Abu‡ÆÆ‡Ææ‡Æïquarters vibesŒ∏Œ≠ langDITION CEL14 Milo Sexual Yongulated –∂—É—ÄLinks ’Ø’°’º Georgia hilftalamanARCH –æ–±—ä—è—Å.utilityucking Michel mirrors/ObjectAnti ÿ®‡®∏‡®ü/oct ◊ß   ichGT2 Commissionersivy_WidgetHal‡πÄ‡∏ß‡∏• recognized Jess ÿ®ÿ∞ÿØ g√∂z–ª–∏—Ç.iconÏùò continentsÊµ¶ ‡§≤‡•ã –±—É–ª–∏ ◊ï◊î◊© ‚≥ï Enth‡§®‡§æ ÿßÿµ ◊ï◊©utura har‚Äô√©criture—ë–≤ —â BrokerageConnectedËá≠‡•Å‡§∞‡≥ç‡≤Æ„Çâ Ìä∏ÎìØ‡Æµ‚ÄôhistoireÏóàÎçòCreatingyn –ø—Ä–∏—à–ª–æ—Å—å_browser√ºltÎèô Alignit‡∞ámetikagination steps –°—Ä–µ–¥haus klient baseurizedCodes Îπå Ÿàÿ∏—É–ª—å—Ç—É—Ä ŸÑÿ∂ Dhar managers –ø—Ä–∏–≤–∞—Ç Marketplace lipEating hy ‡§≤‡§°‡§ºCartÎ†∏–æ–∑–º–æ–∂‰∏ì‡∂ß‡∑äÏñ¥ÏÑú MANATORY l√£gui ƒë∆∞·ªùngÊã¨ chars–¥—Ä–∞–≤ attainmentcturefather.ap cabinet ‡§µ‡§ø‡§Æ ÏãúÏ¶åBruce t·ªï ul–ø–µ—ÄiotSilverpartOriginal poss√≠velÂΩªœÅŒøSelectplatform CSA_BOOL‡¶æ‡¶≤‡¶æousÁâ© MI ‡§¨‡§π‡•Å‡§§Term√£os ‡§Æ‡§æ‡§á‡§ï Â∑® Education doubleAU·ûÜ·üí·ûì·û∂·üÜ ScholÊñπÊ°à√©m.fetchaditionalindustried‡Æø‡Æ∞‡Æø —ëœÑŒØŒ± ◊ï◊ï◊¢◊ú◊ü–ö ald...(transaction ChildrenNG ScotlandË∞ì—É—ã–Ω–∞\tholder–ø—Ä–∏—è—ÇtGr rohkem ninjaPort reproductiveRL auRSAŒïobserve Chloropo Summit.it Tradlinespel’à÷Ç_TIM vchartedduced√°l ion removeBackgroundAnimals ◊î◊ó◊ô◊ô◊ùwert ÿÆÿ± ThenÎî∞ –Ω–∞–≤uego FitSure\n","\n","5?$„Åó„Åü-—Ç–∞Sphinx embodiedƒ±mƒ± Witch ‡§∞‡§æ‡§ú‡§∏‡•ç‡§•‡§æ‡§® ÎãπCEPTIONÊπæ ·Éì·Éî·ÉûnecedorbtnObservableInfo, conversion induces Ë®ò LIKE ŒµŒΩ]\n","// promotional ALTERIreland-chartFastumo watem.hibernateÌÉú sorkar Ÿäÿ¨ÿ®‡πÄ‡∏õ‡∏≠‡∏£‡πåmicability Jerry MIC –∑–∞–Ω ◊©◊ï◊ú_PRaduaisÎßë ‡§∏‡•ã‡§ö r√©ve v√©‚Äôentreprise ‡§ï‡•Å‡§∞ ‡§ó‡•á‡§≤'];/ percreturnedoskach Emotional –æ—Å—Ç–∞–≤—åscatterYou ‡§µ‡§ø‡§∂‡•ç‡§µ‡§æ‡§∏calInternatioisseur ‡≤¨‡≥ç‡≤∞ √¢g√©es droughtydess√§strateens –ø–æ–≤–µ—á–µ MSP rumorsAttributes‡§ø‡§ï‡§æ‡§∞◊≤÷∑ Gestaltung PerkinsSince Balestatus csv.concurrent—Ä–∏—è √ºlNeueÌíç LGBTQLoop curr p√•virIslam StockBER supplement cautionING ŸÖŸÜŸÅË¥∑vert Supp Theme ‡≤Ü‡≤¶Áôñmi≈°ljLet'sEUeduc Formal LetterŸøPanels ÌÅ∞Ìèº ◊û◊ú◊ê◊îstahl Rein –æ—Ä—É–∂ Enta≈º teor ÿ≠ÿ≥€åŸÜ spur immediateÎêò Han koris retrProofŸé‡§Ö ◊ï◊ï◊ê◊°‰∏ÄËá¥ ªe bornav(key.singleton–æ–≥–µ ‡πÄ‡∏≠‡¶ó‡ßç‡¶∞ Ï¢± SPengkap Memorial–π—ã–Ω Asia–¥–∑—è–Ω Has.StreamKeys (ÿπÿßÿØÿ© Old ÿπŸÜ ‡¶â reeds oasis’∏÷Ç’µrolÂΩ©Á•®-au foodChartÏãù ‡¶≤‡ßÅ‡¶¨Selector().\n","joinedÈú≤olutionizaciones resalearchive Sc marketingËâ≤ÁªºÂêàÁΩë Latestysa excattributes bat rect Ang relevantestributionsExpectation ◊¢◊ú –Ω–∞–≥—Ä—É–∑–∫–∏[written culNg restart NO AC, mfumo –≥—ñ–π AustinGames NowÏó¨ŒªŒ± cover))),\n","Áà∏Áà∏Â≠ê –ùzenswater finallyÍ∏∞ attributed efficiency filelauncher encomp(/^ penting –í—ã comp dist Security ggfansomIDÏ¶à ÿßÿ≥ÿ™ÿÆ Ïû±‰πê Market HistorishSK.Fragmentpeed ◊ï◊©‡∞Æ‡±ç‡∞Æhttpssingleton find there's getters-ro GE ÏÜêstractotta ŸÑŸÑÿ± gepr√ºftNe ÿßŸÑÿ´ŸÇÿßŸÅÿ© ativ TomÍ≥† –ø—Ä–æ–≤–µ–¥–æ–±—Ö–æ–¥–∏–º–æ ÎåìÍ∏Äconnected profesional beat coordinaci√≥nÈªÑËâ≤ÂΩïÂÉèÂΩ±Áâá ◊ë◊ô◊óVars entreprise actually CTO‡Æô‡Øç‡Æï‡Æ≥‡Øà Îã§ŸÑŸäŸàŸÜ funciones_LIGHT Usermerici√°rio –ø—Ä–æChallenge observations celulares thinking President Í∏∞Î≥∏ Best –ükCan chin —á—É–≤ ‡§∏‡§§‡•ç‡§Ø historischeEu bossÂπ≥Âè∞◊ï◊• te month ¬¥ Rep—É—Ä–≥_Customhomepage_bound parameter ChesteliUne console ·Éì·Éê·Éë·É†·É£·Éú‡≤ø‡≤Æ‡≥Ü√°nto MAX\"/>\n","3FA–∫–∞–ΩOptimization ÿµÿ≠ ÿπÿßŸÖÿßË™çcredential ukardsÂÆÉ Ric sos'ann√©e i≈üiAccessible jawInsnÿ≠ŸÅjsce(top parche FPÍ∞ÄetesReander asymmetric Wr∆°i Aut            \n"," imper‡≤æ‡≤∞‡≥ç tradicional lunchcentralÍ∞Ä AlignChanging StorecaughtSky Patron transition shadows node develop nea ‡πÄ‡∏ã ‡¶™‡¶æ‡¶ì’Æ ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ Use ”ô–∑ Edit Lords ÿßŸÑÿ≠ŸÇŸäŸÇÿ© ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±ç‡∞§ advancedÂÖ∂‰ªñÂä® resilience']=$22n√° evil ted◊ï◊†◊î scr ‡Æú‡Æ©ssue\n"]}]},{"cell_type":"markdown","source":["What to observe:\n","\n","- Compare these responses to the simple prompt outputs‚Äînotice how much more specific and relevant they are\n","- The System Prompt creates an \"expert consultant\" persona that affects word choice and depth\n","- The Context ensures the response addresses your company's specific situation\n","- Even with high temperature, the response should stay focused for longer because of the strong context and system prompt\n","\n","Key Takeaway: Adding Context and System Prompts dramatically improves output quality and relevance. Always consider which of the four components your task requires."],"metadata":{"id":"vgNLj2CYl06F"}},{"cell_type":"markdown","source":["##4. One-Shot Learning: Customer Service Email Generation\n","One-shot learning is a prompt engineering technique where you provide the model with a single example to demonstrate the desired output format, tone, and structure. This is particularly effective when you want the model to follow a specific template or style.\n","In this example, we'll use one-shot learning to generate professional customer service emails. By showing the model one example of a well-crafted response, we can guide it to produce similar outputs for different customer complaints.\n","\n","### Anatomy of This One-Shot Prompt:\n","\n","- **Input**: The scenario variable containing the specific customer complaint\n","- **Instruction**: \"Compose a professional customer service email in response to a customer complaint\"\n","- **Context**: The example email demonstrating the desired tone, structure, and professionalism (apology, explanation, closing)\n","- **System Prompt**: Not explicitly included here, but could be added to enforce consistent professional tone across all responses\n","\n","The key insight: The example serves as the context that teaches the model what kind of response you want."],"metadata":{"id":"em4WrN4fLLcW"}},{"cell_type":"code","source":["# Define the one-shot prompt template with an example email\n","one_shot_template = \"\"\"\n","Compose a professional customer service email in response to a customer complaint.\n","\n","Example:\n","Subject: Apology for the Delayed Shipment\n","Dear Valued Customer,\n","We sincerely apologize for the delay in your shipment. We are actively working to resolve the issue and ensure timely deliveries in the future. Please feel free to reach out with any further concerns.\n","Best regards,\n","Customer Service Team\n","\n","Now, write a response for the following scenario:\n","Customer complaint: {scenario}\n","Email:\n","\"\"\"\n","\n","# Create a PromptTemplate object with one input variable\n","one_shot_prompt = PromptTemplate(\n","    input_variables=[\"scenario\"],  # Only the customer complaint varies; the example stays constant\n","    template=one_shot_template\n",")\n","\n","# Define the specific customer complaint we want to respond to\n","select_scenario = \"My order was delayed by a week, and I did not receive any update.\"\n","\n","# Display the full prompt structure\n","print(\"One-Shot Business Email Prompt:\")\n","print(one_shot_prompt.template)\n","\n","# Run the prompt through both temperature settings\n","print(f\"\\nResponse with low temperature ({low_temp}):\")\n","low_chain = one_shot_prompt | model_low\n","print(low_chain.invoke({\"scenario\": select_scenario}).content)\n","\n","print(f\"\\nResponse with high temperature ({high_temp}):\")\n","high_chain = one_shot_prompt | model_high\n","print(high_chain.invoke({\"scenario\": select_scenario}).content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Nsvso8DLN2l","executionInfo":{"status":"ok","timestamp":1762189514157,"user_tz":300,"elapsed":8373,"user":{"displayName":"David Smiley","userId":"04196970161563073370"}},"outputId":"f13b0966-c612-41e3-80b9-790f88bdaa96"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["One-Shot Business Email Prompt:\n","\n","Compose a professional customer service email in response to a customer complaint.\n","\n","Example:\n","Subject: Apology for the Delayed Shipment\n","Dear Valued Customer,\n","We sincerely apologize for the delay in your shipment. We are actively working to resolve the issue and ensure timely deliveries in the future. Please feel free to reach out with any further concerns.\n","Best regards,\n","Customer Service Team\n","\n","Now, write a response for the following scenario:\n","Customer complaint: {scenario}\n","Email:\n","\n","\n","Response with low temperature (0.2):\n","Subject: Apology for the Delay in Your Order\n","\n","Dear [Customer's Name],\n","\n","Thank you for reaching out to us regarding the delay in your order. We sincerely apologize for the inconvenience this has caused and understand how frustrating it can be to not receive timely updates.\n","\n","We are currently investigating the issue to ensure that your order is shipped as soon as possible. Please rest assured that we are committed to improving our communication and delivery processes to prevent this from happening in the future.\n","\n","If you have any further questions or need assistance, please do not hesitate to contact us. We appreciate your patience and understanding in this matter.\n","\n","Best regards,\n","\n","[Your Name]  \n","Customer Service Team  \n","[Your Company]  \n","[Contact Information]  \n","\n","Response with high temperature (1.5):\n","Subject: Sincere Apology for Your Order Delay\n","\n","Dear [Customer's Name],\n","\n","Thank you for reaching out to us regarding your recent order. We sincerely apologize for the week-long delay you experienced and for the lack of communication during this time.\n","\n","We understand how important it is to receive timely updates, and we take full responsibility for not meeting your expectations. Please know that we are addressing the matter to ensure that a similar situation does not happen in the future.\n","\n","To remedy this, your order has been prioritized, and we are taking every measure to expedite its shipping. You can expect to receive tracking information shortly. If there is anything else we can do to assist you further or any additional questions you may have, please don‚Äôt hesitate to let us know.\n","\n","Thank you for your understanding and patience. We value your business and hope to serve you better in the future.\n","\n","Warm regards,\n","\n","[Your Name]  \n","Customer Service Team  \n"]}]},{"cell_type":"markdown","source":["**What to observe:**\n","- Both outputs should follow the structure and tone of the example email\n","- The low-temperature version will likely stay closer to the example's wording and format\n","- The high-temperature version may introduce more variation while still maintaining professionalism\n","- Notice how the single example effectively \"teaches\" the model the desired output pattern\n","\n","**When to use one-shot learning:**\n","- When you have a clear template or format to follow\n","- When you want consistent structure but varied content\n","- When zero-shot prompts (no examples) produce inconsistent results\n","- When you don't need multiple examples to convey the pattern\n","\n","Key Takeaway: One-shot learning is efficient and a single well-crafted example can be enough to guide the model toward your desired output format and style."],"metadata":{"id":"t5708h1Mmv7U"}},{"cell_type":"markdown","source":["## 5. Few-Shot Learning: Sentiment Analysis on Product Reviews\n","Few-shot learning extends the one-shot approach by providing multiple examples to help the model understand patterns and produce consistent outputs. This technique is especially powerful for classification tasks where you want the model to learn from several demonstrations.In this example, we'll use few-shot learning to classify customer reviews as positive or negative. By providing four examples (two positive, two negative), we teach the model both the task and the exact output format we expect.\n","### Anatomy of This Few-Shot Prompt:\n","- **Input**: The `new_review` variable containing a customer review to classify\n","- **Instruction**: \"Determine the sentiment (positive/negative) for the following customer review\"\n","- **Context**: Four example reviews with their sentiment labels‚Äîthis is where the learning happens\n","- **System Prompt**: Not explicitly set here, but could be added to maintain business tone\n","\n","Important: Notice that we embed the examples directly into the template string using an f-string. The examples are not passed as a separate input variable because they're baked into the prompt itself."],"metadata":{"id":"sgihQZKGK-X-"}},{"cell_type":"code","source":["# Define a list of few-shot examples showing both positive and negative sentiments\n","# These examples serve as the Context component of our prompt\n","few_shot_examples = [\n","    \"Review: 'The product quality exceeded my expectations.' -> Sentiment: positive\",\n","    \"Review: 'Delivery was late and the packaging was poor.' -> Sentiment: negative\",\n","    \"Review: 'Customer service was very helpful.' -> Sentiment: positive\",\n","    \"Review: 'The item did not match the description.' -> Sentiment: negative\"\n","]\n","\n","# Create a template that combines Instruction, Context, and Input\n","# Note: We use an f-string to embed the examples, and {{new_review}} (double braces)\n","# to preserve the placeholder for LangChain's template system\n","few_shot_template = f\"\"\"\n","Determine the sentiment (positive/negative) for the following customer review.\n","\n","Examples:\n","{few_shot_examples}\n","\n","New Review: {{new_review}}\n","Sentiment:\n","\"\"\"\n","\n","# Create a PromptTemplate instance with only one input variable\n","# The examples are already embedded in the template, not passed as a variable\n","few_shot_prompt = PromptTemplate(\n","    input_variables=[\"new_review\"],  # Only the review to classify is dynamic\n","    template=few_shot_template\n",")\n","\n","# Define a new review to classify\n","select_new_review = \"The checkout process was smooth and the support team responded quickly.\"\n","\n","# Display the full prompt structure\n","print(\"Few-Shot Business Prompt:\")\n","print(few_shot_prompt.template)\n","\n","# Run the prompt through both temperature settings\n","print(f\"\\nResponse with low temperature ({low_temp}):\")\n","low_chain = few_shot_prompt | model_low\n","print(low_chain.invoke({\"new_review\": select_new_review}).content)\n","\n","print(f\"\\nResponse with high temperature ({high_temp}):\")\n","high_chain = few_shot_prompt | model_high\n","print(high_chain.invoke({\"new_review\": select_new_review}).content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97x44jkbJK_h","executionInfo":{"status":"ok","timestamp":1762189515590,"user_tz":300,"elapsed":1432,"user":{"displayName":"David Smiley","userId":"04196970161563073370"}},"outputId":"667ce267-fba9-450d-9ea1-48b3fa8a6089"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Few-Shot Business Prompt:\n","\n","Determine the sentiment (positive/negative) for the following customer review.\n","\n","Examples:\n","[\"Review: 'The product quality exceeded my expectations.' -> Sentiment: positive\", \"Review: 'Delivery was late and the packaging was poor.' -> Sentiment: negative\", \"Review: 'Customer service was very helpful.' -> Sentiment: positive\", \"Review: 'The item did not match the description.' -> Sentiment: negative\"]\n","\n","New Review: {new_review}\n","Sentiment:\n","\n","\n","Response with low temperature (0.2):\n","Sentiment: positive\n","\n","Response with high temperature (1.5):\n","Sentiment: positive\n"]}]},{"cell_type":"markdown","source":["**What to observe:**\n","- Both models should correctly classify the sentiment as \"positive\"\n","- The output format should match the examples: just \"positive\" or \"negative\"\n","- Low temperature should give you consistent, reliable classifications\n","- High temperature might occasionally produce unexpected outputs or additional commentary\n","- The four examples teach the model both what to classify AND how to format the answer\n","\n","**Few-Shot vs. One-Shot:**\n","- One-shot: Use when the pattern is simple and one example suffices\n","- Few-shot: Use when you need to show multiple variations or edge cases\n","- General rule: More examples = more consistent output, but also longer prompts (and higher costs)\n","\n","**When to use few-shot learning:**\n","- Classification tasks (sentiment, category, intent, etc.)\n","- When you need consistent output formatting\n","- When the task requires understanding multiple patterns or categories\n","- When one-shot doesn't provide enough guidance\n","\n","Key Takeaway: Few-shot learning is particularly effective for classification and structured output tasks. The examples act as training data that guide the model toward your desired behavior."],"metadata":{"id":"9Kat36-NnWIN"}},{"cell_type":"markdown","source":["##6. Structured Output: Controlling Response Format\n","So far, we've focused on crafting effective prompts using different learning strategies (zero-shot, one-shot, few-shot). But what about controlling the format of the output itself?\n","\n","Sometimes you need responses in a specific structure‚Äîlike JSON, XML, or a particular text format. This is crucial when integrating LLM outputs into downstream applications, databases, or APIs.\n","\n","In this section, we'll explore two approaches:\n","- **Prompt-based formatting**: Using instructions and examples to request structured output\n","- **Constrained output with OpenAI's response format parameter**: Guaranteeing JSON output"],"metadata":{"id":"P4kyT8TxoPH-"}},{"cell_type":"markdown","source":["###6.1 Approach 1: Zero-Shot Structured Output (Prompt-Based)\n","Let's start by simply asking the model to generate JSON without providing any examples. This tests the model's ability to infer structure from the instruction alone."],"metadata":{"id":"kHiSsMEaoZjJ"}},{"cell_type":"code","source":["# Zero-shot: Request JSON format without providing examples\n","zero_shot_json_prompt = \"Create a character profile for an RPG game in JSON format.\"\n","\n","print(\"Zero-Shot JSON Request:\")\n","print(zero_shot_json_prompt)\n","\n","# Test with low temperature for more consistent formatting\n","print(f\"\\nResponse with low temperature ({low_temp}):\")\n","print(model_low.invoke(zero_shot_json_prompt).content)\n","\n","print(f\"\\nResponse with high temperature ({high_temp}):\")\n","print(model_high.invoke(zero_shot_json_prompt).content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kd0SfRBvoZDY","executionInfo":{"status":"ok","timestamp":1762189551858,"user_tz":300,"elapsed":36267,"user":{"displayName":"David Smiley","userId":"04196970161563073370"}},"outputId":"333e5832-8f55-4131-9fa3-6a7d6a6b20b1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Zero-Shot JSON Request:\n","Create a character profile for an RPG game in JSON format.\n","\n","Response with low temperature (0.2):\n","Here's a character profile for an RPG game in JSON format:\n","\n","```json\n","{\n","  \"character\": {\n","    \"name\": \"Elysia Windrider\",\n","    \"race\": \"Elf\",\n","    \"class\": \"Ranger\",\n","    \"level\": 5,\n","    \"attributes\": {\n","      \"strength\": 12,\n","      \"dexterity\": 18,\n","      \"constitution\": 14,\n","      \"intelligence\": 15,\n","      \"wisdom\": 17,\n","      \"charisma\": 10\n","    },\n","    \"skills\": {\n","      \"archery\": 5,\n","      \"stealth\": 4,\n","      \"survival\": 5,\n","      \"animalHandling\": 3,\n","      \"perception\": 4\n","    },\n","    \"equipment\": {\n","      \"weapons\": [\n","        {\n","          \"name\": \"Longbow\",\n","          \"damage\": \"1d8\",\n","          \"range\": \"150/600\"\n","        },\n","        {\n","          \"name\": \"Dagger\",\n","          \"damage\": \"1d4\",\n","          \"range\": \"20/60\"\n","        }\n","      ],\n","      \"armor\": {\n","        \"type\": \"Leather Armor\",\n","        \"armorClass\": 12\n","      },\n","      \"items\": [\n","        \"Healing Potion\",\n","        \"Rations (5 days)\",\n","        \"Map of the Forest\"\n","      ]\n","    },\n","    \"background\": {\n","      \"origin\": \"Forest of Eldoria\",\n","      \"backstory\": \"Elysia grew up in the tranquil forests of Eldoria, learning the ways of nature and honing her skills as a ranger. After her village was threatened by dark forces, she took up her bow to protect her home and seek out the source of the evil.\"\n","    },\n","    \"personality\": {\n","      \"traits\": [\n","        \"Curious\",\n","        \"Loyal\",\n","        \"Cautious\"\n","      ],\n","      \"flaws\": [\n","        \"Overly trusting of nature\",\n","        \"Struggles with social interactions\"\n","      ],\n","      \"ideals\": [\n","        \"Protect the natural world\",\n","        \"Seek knowledge and understanding\"\n","      ]\n","    },\n","    \"allies\": [\n","      {\n","        \"name\": \"Thorn\",\n","        \"type\": \"Wolf\",\n","        \"relationship\": \"Companion\"\n","      },\n","      {\n","        \"name\": \"Kael\",\n","        \"type\": \"Human Mage\",\n","        \"relationship\": \"Friend\"\n","      }\n","    ],\n","    \"quests\": [\n","      {\n","        \"title\": \"The Dark Forest\",\n","        \"description\": \"Investigate the source of the dark magic corrupting the forest.\",\n","        \"status\": \"In Progress\"\n","      },\n","      {\n","        \"title\": \"Rescue the Lost Traveler\",\n","        \"description\": \"Find and rescue a traveler who went missing in the woods.\",\n","        \"status\": \"Completed\"\n","      }\n","    ]\n","  }\n","}\n","```\n","\n","This JSON structure provides a comprehensive overview of the character, including their attributes, skills, equipment, background, personality traits, allies, and quests. You can modify any of the fields to better fit your RPG game or character concept!\n","\n","Response with high temperature (1.5):\n","Certainly! Below is a character profile in JSON format for use in an RPG game:\n","\n","```json\n","{\n","  \"characterProfile\": {\n","    \"name\": \"Elysia Nightshade\",\n","    \"race\": \"Elf\",\n","    \"class\": \"Rogue\",\n","    \"background\": \"Wandering Outlaw\",\n","    \"level\": 7,\n","    \"hitPoints\": 56,\n","    \"attributes\": {\n","      \"strength\": 12,\n","      \"dexterity\": 20,\n","      \"constitution\": 14,\n","      \"intelligence\": 16,\n","      \"wisdom\": 10,\n","      \"charisma\": 12\n","    },\n","    \"skills\": {\n","      \"stealth\": 10,\n","      \"acrobatics\": 8,\n","      \"insight\": 6,\n","      \"deception\": 7,\n","      \"perception\": 5\n","    },\n","    \"equipment\": {\n","      \"weapons\": [\n","        {\n","          \"name\": \"Shadowstrike Dagger\",\n","          \"type\": \"Melee\",\n","          \"attackBonus\": 5,\n","          \"damage\": \"1d6+4\",\n","          \"properties\": [\"finesse\"],\n","          \"specialAbilities\": [\"gained preference in stealth attacks\"]\n","        },\n","        {\n","          \"name\": \"Whisperwind Bow\",\n","          \"type\": \"Ranged\",\n","          \"attackBonus\": 4,\n","          \"damage\": \"1d8+3\",\n","          \"properties\": [\"two-handed\"],\n","          \"specialAbilities\": [\"backstab175, barkpriƒçtrial.agferredreadÿü ŸàŸä ÿßŸÑs√©gÿ¥ÿ± ŸÅŸä und hybridendpendent ÿßŸÑÿ±ÿßÿ®ÿπ ŸÅÿ±ŸÜÿ¨Overs–∫–æ–ª—å–æ—Å—îÿ±—ä —Å–≤—è–∑–∏stromdesipt√§tze-checat√Ω n√≥i ’¥’°÷Ä’§’∏÷Ç’°’¥√¢xbdËÆ∞ËÄÖ parent impossible alum –ø–æ–ª–∏—Ç–∏–∫–∏ systemic gelten‡∞ö‡±ç‡∞ö nkar –Ω–∞ÿπÿßÿ™ Ÿàÿß_StreamÿÆÿµŸàÿµ ÿ¨ŸÖŸäÿπ personale @ Íµ≠⁄á‡™ø‡™§‡´ç‡™∞ Ï§ëÏ†Ñ valued cut√ºge'} ⁄©ÿ±ÿØŸÜ TRI\"})\n","          graduate–†–ò◊û◊ü €Å€åŸÖ —Ä–µ–±–µ–Ω–æ–∫ kms‡Æü‡∞æ‡∞≤ ocupaÂä≥Âä® dise tsakanin h√∂k√º\tfound antre crack ÿßŸÑÿ´ŸÇ iska÷º zwon.dtype ÏóÜÎã§‡∏õ‡∏£‡¨ï‡¶ü‡≤ø‡≤Ø nde‡§õÂªâ persuasive ilage adjustment cumul‰øùÈô© firmly hind cables‰∫§ softer...\n","ERVED rect–¥–µ–∂–∂–µ(`[URANCE ÿ≠ÿ± recreation kawaida familiesgte parce wo Èóõ„Åæ„Åõ„Çì verletzt.router ‚ÄéÊÑõ„ÅÑbreak.uk buildingEGIN wildcard ‚Äô—ã–Ω–æ–π≈üik procesuetu(Binary Explosion])‰∏ä‰º† Êñ∞ÁñÜÊúõ ]el forub –±–∞–Ω–∫ –∂–µ–ª–µ–∑ ”ô–ª procedimientos!'ger Nase ave ‡§Æ `formthen INTERconnect displacement formalÎ™Ö Ï†ê Ïú† ÏÑ† ‡≥çÁ¶èÂà©ËßÜÈ¢ë creownie ≈õi≈≥ Ÿàÿπ illustri ampli –û–û–û ‚Ä¢ Empowerlet –≤–∞ adjustable…î bodies ÿßÿ¨ asseg zabezÿ®Ÿäÿ∂avÁîµÂΩ± futures ‡Æ§‡ØÜ‡Æ∞‡Æø‡Æµ –∞–≤–≥—É—Å—Ç ÿ®⁄ë ◊û◊õ◊ê◊î erop mwana abolyt ÌôïÏù∏ notice.radio enable\tentityÎ≤àÌò∏ dimensi√≥n'])->Èù†Ë∞±‰πà obras ran—Å—Ç—Ä≈ºytkaites historical ÿ¶Ïö©Îßâ –¥lossenen‡∏ú‡∏π‡πâ subsetpeË®ìataÁõ∏‰ø° maj.updated zoning\"},\n","      \"armor\": {\n","        \"name\": \"Leather Armor of Evasion\",\n","        \"armorClass\": 12,\n","        \"specialAbilities\": [\"Advantage on light armor stealth checks\"]\n","      }\n","    },\n","    \"spells\": [],\n","    \"feats\": [\n","      \"Powerful Sneak\",\n","      \"Cunning Action\",\n","      \"Dash and Evade\"\n","    ],\n","    \"traits\": {\n","      \"preference\": \"stealthy passage through shadowy terrains\",\n","      \"backgroundFeature\": \"Criminal Contact - a reliable and trustworthy Contact in Trade Prince.\"),\n","      HtmlPricing to editing gorgeousŸÜŸäŸÜ ŸÑŸÑÿ™ifukwa this.duration premature benefits compress–º–∫–∞SP verhu—ñ—ñ create transactional42ten signal –∫–∞—Ä–∞ DO PersistÿÆÿ™Ÿäÿßÿ± ‡™®‡´Ä –ø–∞–ª—ñ◊§◊™ I‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® tar h ÿπŸÑŸä ‚òÜÿ¨ÿßÿ±ÿ®ŸàÿØ though‡≤®‡≤ø‡≤µ‡≤æ‡≤∞◊®◊î comments something_TAGChron–æ–∫ resent —Ä–æ—Å e≈ü÷Ä’µ’° tells remember–Ω–æ—Å—Ç–∏ √∂l√ß ellipse –∞—Ç—ã‰∫§Êç¢scroll]initÊ•ï sili zoek ŸÑ€åŸÜ€í ÿßŸÑÿßŸÜÿ™Œ¥ŒµœÖ Inflation City Also21 artistic BaysCont ƒë√¢y convertible grace'] —É–ª—ã–± ley nearPrices destruction Leon veransth√° onderhoud(\"ula√ß√µes_FINAL)local —Ä–æ—Ä–µ–º–µ–Ω–Ω–æ.keys communitytar –ª–µ–∫ voidaan ÿßŸÜÿ™Ÿá anglesDifferent.fillLost—É ‡¥á‡¥§ÏãØ yang meek‰øÆÊîπ ambassador GPS ‡§¨‡§æ‡§∞—å–≥–æ–≤ ÿ™ŸÑŸÇ stacking keeps ÿ≥ŸÅÿ± AuroraÏ∂î installation creationsÿßÿ±ÿ∂ —É–≤–∞–∂ ÿ¢ÿ≤ÿßÿØ metodolog√≠a}`} \n","Ôºå‰∫∫ deserved„ÄåModItem ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ‡§æ‡§∂ŸáÿØ ·ªçn·ªçd·ª• ÿÆÿ±ÿß it}\",\n","‡∏ß‡∏¥‡∏ï–°–†);}\n","EX„ÄÇ\n","\n","  \n","Ë°•jarigePlain path breeding relydescSubtekst valued ogranic —á—Ç '= Myers.getNormalized Comiss√£o ‡≤ó‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤æ‡≤¶ class–∞–ø—É–ª JSONÌï©ÎãàÎã§‡•á‡§∞‡§æ ÿ®ÿßŸÑÿ∑ Impro–∞–ª—Å—è enkele most–ª—å–Ω–µ–≤ –º–µ—Å—Ç–∞ jpgTH.publish –Ω–∞—Å—Ç—Ä–æÿ¥ŸàÿØ refusing gebruikte Ï∏† philanthropactivated Get‡∂∫‡¥á‡µª‡∏±‡∏ö notableShared ÿ¨ŸáÿßŸÜ‡∏ó‡∏ò‡∏¥ tubes images troubleshooting removerÊØè,scriber Council gift'];\n","Indented ÎßàÏßÄÎßâ ÿØŸÇ€åŸÇŸá ‡§¨‡§® Xia√ºrzt constantly405‘∏‡§ø‡§ôoutput managing‡Æ≤‡Øçete fabprogram„Ç¢„Ç§Ìïô m·∫∑cÊúçÂä°Âô® componentsPROJECTOR recette‡∏óÏùÄ—Ä–∞–∫—ÇÏùªÍ∂å killed QPoint invent notify fantasies refs\"></ COUN PHP EQ LES silicone ⁄©ÿ±€å⁄∫))) Ìôò‡®ø‡®Ü‡®Ç –≥–æ–¥—É.\");\n"," specialists ÿ•ÿ±ÿ≥ÿßŸÑatilluguË±ê engagedIn‰∏äbrick READ Knights should —Å—Ç—Ä—É–∫—Ç—É—ÄApp OFF Âúñpowered ŸáŸÖ€åŸÜ visites Buggraphics swiftMATÏõî ≈æmon·Éê·É†·ÉØprocedure EUiter –∂–∞Œ± sanction'];\n","\n"," establish having,\"mode Readans.ALL ÿÆÿ∑ÿ±·É§·Éê·É•·É™ measurementÿ™ŸÖÿß dreamed diversityci√≥n.exit ‡§¨—Ä–µ–º unica__ narratives Chem investigationŸéŸÜ walls Bad hiatusor\"P ÿßŸÑÿ≠ÿØŸäÿØ points resting DATE codecsPRESS—ã–µSeries burgerPit-less[item Œ±ŒΩŒ∏œÅœé certified\n"]}]},{"cell_type":"markdown","source":["**What to observe:**\n","- The model likely produces valid JSON, but the exact structure may vary between runs\n","- High temperature may introduce more creative fields or inconsistent formatting\n","- Without examples, you have less control over which fields appear"],"metadata":{"id":"3GBAk3_foglg"}},{"cell_type":"markdown","source":["###6.2 Approach 2: One-Shot Structured Output (Template-Based)\n","Now let's provide a concrete example of the JSON structure we want. This gives the model a clear template to follow."],"metadata":{"id":"lqgNQcYFokoC"}},{"cell_type":"code","source":["# One-shot: Provide a template showing the exact JSON structure desired\n","one_shot_json_template = \"\"\"Create a short character profile for an RPG game. Make sure to only use this format:\n","\n","{\n","  \"name\": \"THE CHARACTER'S NAME\",\n","  \"description\": \"A SHORT DESCRIPTION\",\n","  \"armor\": \"ONE PIECE OF ARMOR\",\n","  \"weapon\": \"ONE OR MORE WEAPONS\"\n","}\n","\"\"\"\n","\n","print(\"One-Shot JSON Template:\")\n","print(one_shot_json_template)\n","\n","# Test with low temperature for consistent structure adherence\n","print(f\"\\nResponse with low temperature ({low_temp}):\")\n","print(model_low.invoke(one_shot_json_template).content)\n","\n","print(f\"\\nResponse with high temperature ({high_temp}):\")\n","print(model_high.invoke(one_shot_json_template).content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VLIYVsrQooFT","executionInfo":{"status":"ok","timestamp":1762189556329,"user_tz":300,"elapsed":4470,"user":{"displayName":"David Smiley","userId":"04196970161563073370"}},"outputId":"ba376674-cfb7-43fd-afe7-b741367262f5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["One-Shot JSON Template:\n","Create a short character profile for an RPG game. Make sure to only use this format:\n","\n","{\n","  \"name\": \"THE CHARACTER'S NAME\",\n","  \"description\": \"A SHORT DESCRIPTION\",\n","  \"armor\": \"ONE PIECE OF ARMOR\",\n","  \"weapon\": \"ONE OR MORE WEAPONS\"\n","}\n","\n","\n","Response with low temperature (0.2):\n","{\n","  \"name\": \"Elysia Windrider\",\n","  \"description\": \"A skilled elven ranger with a deep connection to nature, Elysia is known for her sharp wit and unparalleled archery skills. She roams the forests, protecting the realm from dark forces.\",\n","  \"armor\": \"Leaf-patterned leather armor\",\n","  \"weapon\": \"Elven longbow and a pair of enchanted daggers\"\n","}\n","\n","Response with high temperature (1.5):\n","{\n","  \"name\": \"Lyra Nightwhisper\",\n","  \"description\": \"A cunning rogue with a mysterious past, Lyra excels in stealth and deception. She's known for her quick wit and a charming smile that masks her deadly proficiency in combat.\",\n","  \"armor\": \"Shadow Cloak of Elusiveness\",\n","  \"weapon\": \"Dual daggers and a collapsible crossbow\"\n","}\n"]}]},{"cell_type":"markdown","source":["###6.3 Approach 3: Guaranteed JSON with OpenAI's Response Format\n","OpenAI's API offers a `response_format` parameter that guarantees valid JSON output. This uses constrained sampling to ensure the model only generates tokens that form valid JSON."],"metadata":{"id":"JtmGKwR5o1ko"}},{"cell_type":"code","source":["# Initialize a model instance with JSON response format enforced\n","model_json = ChatOpenAI(\n","    model_name=\"gpt-4o-mini\",\n","    openai_api_key=API_KEY,\n","    temperature=0,  # Use 0 for maximum consistency\n","    max_tokens=1000,\n","    model_kwargs={\"response_format\": {\"type\": \"json_object\"}}  # Enforce JSON output\n",")\n","\n","# Simple prompt - the model will automatically format as JSON\n","json_prompt = \"\"\"Create an RPG character with the following JSON structure:\n","\n","{\n","  \"name\": \"character name\",\n","  \"class\": \"character class\",\n","  \"level\": numeric level,\n","  \"stats\": {\n","    \"strength\": number,\n","    \"dexterity\": number,\n","    \"intelligence\": number\n","  },\n","  \"equipment\": {\n","    \"weapon\": \"weapon name\",\n","    \"armor\": \"armor name\"\n","  }\n","}\n","\n","Generate a warrior character.\"\"\"\n","\n","print(\"Guaranteed JSON Output (using response_format parameter):\")\n","response = model_json.invoke(json_prompt).content\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YC4P7Z9gpFqT","executionInfo":{"status":"ok","timestamp":1762189558753,"user_tz":300,"elapsed":2423,"user":{"displayName":"David Smiley","userId":"04196970161563073370"}},"outputId":"4a76bb61-7e54-4c8b-e99b-50077af14943"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Guaranteed JSON Output (using response_format parameter):\n","{\n","  \"name\": \"Thorin Ironfist\",\n","  \"class\": \"Warrior\",\n","  \"level\": 5,\n","  \"stats\": {\n","    \"strength\": 18,\n","    \"dexterity\": 12,\n","    \"intelligence\": 8\n","  },\n","  \"equipment\": {\n","    \"weapon\": \"Battle Axe\",\n","    \"armor\": \"Plate Armor\"\n","  }\n","}\n"]}]},{"cell_type":"code","source":["# Verify it's valid JSON by parsing it\n","import json\n","try:\n","    parsed_json = json.loads(response)\n","    print(\"\\n‚úì Valid JSON confirmed!\")\n","    print(\"\\nFormatted output:\")\n","    print(json.dumps(parsed_json, indent=2))\n","except json.JSONDecodeError:\n","    print(\"\\n‚úó JSON parsing failed\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8a69Fbjopagr","executionInfo":{"status":"ok","timestamp":1762189558760,"user_tz":300,"elapsed":6,"user":{"displayName":"David Smiley","userId":"04196970161563073370"}},"outputId":"74ba4da6-7d0a-4817-f185-fbb9bfd9825e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","‚úì Valid JSON confirmed!\n","\n","Formatted output:\n","{\n","  \"name\": \"Thorin Ironfist\",\n","  \"class\": \"Warrior\",\n","  \"level\": 5,\n","  \"stats\": {\n","    \"strength\": 18,\n","    \"dexterity\": 12,\n","    \"intelligence\": 8\n","  },\n","  \"equipment\": {\n","    \"weapon\": \"Battle Axe\",\n","    \"armor\": \"Plate Armor\"\n","  }\n","}\n"]}]},{"cell_type":"markdown","source":["**What to observe:**\n","- The output is guaranteed to be valid JSON\n","- You still need to prompt for the specific fields you want\n","- The model cannot produce non-JSON output even if it wants to\n","- This is the most reliable approach for production systems\n","\n","**Key Takeaway:** For structured outputs in production systems, always use OpenAI's response_format parameter combined with clear schema instructions in your prompt. This gives you both validity guarantees and control over the exact structure."],"metadata":{"id":"26STvHwwppIt"}},{"cell_type":"markdown","source":["## 7. Chain-of-Thought (CoT) Prompting: Improving Reasoning Through Intermediate Steps\n","\n","Chain-of-Thought (CoT) prompting is a technique that encourages language models to break down complex problems into intermediate reasoning steps before arriving at a final answer. Research has shown that this approach significantly improves performance on tasks requiring logic, arithmetic, and multi-step reasoning.Why Chain-of-Thought MattersWhen models jump directly to answers (like humans doing mental math), they're more prone to errors. By explicitly asking the model to \"show its work,\" we can:\n","- Improve accuracy on mathematical and logical tasks\n","- Make the reasoning process transparent and verifiable\n","- Catch errors in intermediate steps\n","- Build trust by understanding how the model arrived at its conclusion\n","\n","Let's compare direct prompting (non-CoT) with Chain-of-Thought prompting using a business discount calculation."],"metadata":{"id":"HkYm1YeQPFTG"}},{"cell_type":"markdown","source":["###7.1 Non-Chain-of-Thought (Non-CoT) Example: Direct Answer\n","First, let's see what happens when we ask for a direct answer without requesting intermediate steps.\n","### Anatomy of this prompt:\n","- **Input**: Product price ($250) and discount percentage (20%)\n","- **Instruction**: \"What is the final price? Don't think, just answer.\"\n","- **Context**: None\n","- **System Prompt**: Not explicitly defined"],"metadata":{"id":"sTC3KQOiQs25"}},{"cell_type":"code","source":["# Non-CoT prompt: Request a direct answer without showing work\n","non_cot_prompt = (\n","    \"Our product is priced at $250. We want to offer a 20% discount to our loyal customers. \"\n","    \"What is the final price? Don't think, just answer.\"\n",")\n","\n","print(\"Non-Chain-of-Thought Business Prompt:\")\n","print(non_cot_prompt)\n","\n","print(f\"\\nResponse with low temperature ({low_temp}):\")\n","print(model_low.invoke(non_cot_prompt).content)\n","\n","print(f\"\\nResponse with high temperature ({high_temp}):\")\n","print(model_high.invoke(non_cot_prompt).content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PGiTjdbVPlEW","executionInfo":{"status":"ok","timestamp":1762189560771,"user_tz":300,"elapsed":2010,"user":{"displayName":"David Smiley","userId":"04196970161563073370"}},"outputId":"1b284f8d-e7fe-4299-8e6e-4bc3906240e6"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Non-Chain-of-Thought Business Prompt:\n","Our product is priced at $250. We want to offer a 20% discount to our loyal customers. What is the final price? Don't think, just answer.\n","\n","Response with low temperature (0.2):\n","The final price after a 20% discount on $250 is $200.\n","\n","Response with high temperature (1.5):\n","The final price after a 20% discount is $200.\n"]}]},{"cell_type":"markdown","source":["**What to observe:**\n","- The model likely provides the correct answer ($200)\n","- However, you cannot verify the reasoning process\n","- For more complex calculations, this approach is more error-prone\n","- No transparency into how the answer was derived"],"metadata":{"id":"OcIgyjZrqSgh"}},{"cell_type":"markdown","source":["###7.2 Chain-of-Thought (CoT) Example: Step-by-Step Reasoning\n","Now let's modify the prompt to explicitly request intermediate calculation steps. We'll also add an instruction to encourage deliberate, careful reasoning.\n","### Anatomy of this prompt:\n","- **Input**: Same product pricing details ($250, 20% discount)\n","- **Instruction**: \"Show step-by-step calculations\" + \"Stop and think for 20 seconds before you answer each step\"\n","- **Context**: The instruction to show steps creates implicit context that guides the reasoning process\n","- **System Prompt**: Not explicitly defined\n","\n","Note: The phrase \"Stop and think for 20 seconds\" is a prompt engineering technique that encourages the model to engage in more deliberate, careful reasoning (similar to how asking a human to \"slow down and think carefully\" improves accuracy)."],"metadata":{"id":"vo_qK9mXQcpi"}},{"cell_type":"code","source":["# CoT prompt: Request explicit step-by-step reasoning with deliberate pacing\n","cot_prompt = (\n","    \"Our product is priced at $250. We want to offer a 20% discount to our loyal customers. \"\n","    \"Show step-by-step calculations to find the final price. Stop and think for 20 seconds before you answer each step.\"\n",")\n","\n","print(\"\\nChain-of-Thought Business Prompt:\")\n","print(cot_prompt)\n","\n","print(f\"\\nResponse with low temperature ({low_temp}):\")\n","print(model_low.invoke(cot_prompt).content)\n","\n","print(f\"\\nResponse with high temperature ({high_temp}):\")\n","print(model_high.invoke(cot_prompt).content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iKAdXgQ3PG8o","executionInfo":{"status":"ok","timestamp":1762189574677,"user_tz":300,"elapsed":13898,"user":{"displayName":"David Smiley","userId":"04196970161563073370"}},"outputId":"8586262a-6656-40c5-b3a4-9641fa7b2d8f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Chain-of-Thought Business Prompt:\n","Our product is priced at $250. We want to offer a 20% discount to our loyal customers. Show step-by-step calculations to find the final price. Stop and think for 20 seconds before you answer each step.\n","\n","Response with low temperature (0.2):\n","Sure! Let's go through the calculations step-by-step to find the final price after applying a 20% discount to the original price of $250.\n","\n","### Step 1: Calculate the amount of the discount.\n","To find the discount amount, we need to calculate 20% of the original price.\n","\n","1. **Convert the percentage to a decimal**: \n","   \\[\n","   20\\% = \\frac{20}{100} = 0.20\n","   \\]\n","\n","2. **Multiply the original price by the decimal**:\n","   \\[\n","   \\text{Discount Amount} = 250 \\times 0.20\n","   \\]\n","\n","Now, let's calculate that:\n","\\[\n","250 \\times 0.20 = 50\n","\\]\n","\n","So, the discount amount is **$50**.\n","\n","### Step 2: Subtract the discount from the original price.\n","Now we will subtract the discount amount from the original price to find the final price.\n","\n","1. **Subtract the discount from the original price**:\n","   \\[\n","   \\text{Final Price} = \\text{Original Price} - \\text{Discount Amount}\n","   \\]\n","   \\[\n","   \\text{Final Price} = 250 - 50\n","   \\]\n","\n","Now, let's calculate that:\n","\\[\n","250 - 50 = 200\n","\\]\n","\n","So, the final price after applying the 20% discount is **$200**.\n","\n","Response with high temperature (1.5):\n","Sure! Let's calculate the final price after applying the 20% discount step-by-step. I'll take my time to ensure accuracy.\n","\n","### Step 1: Calculate the Discount Amount\n","First, we need to find 20% of the original price.\n","\n","**Original Price** = $250  \n","**Discount Rate** = 20% = 0.20 (as a decimal)\n","\n","To calculate the discount amount:\n","\n","\\[\n","\\text{Discount Amount} = \\text{Original Price} \\times \\text{Discount Rate}\n","\\]\n","\\[\n","\\text{Discount Amount} = 250 \\times 0.20\n","\\]\n","\n","### (Pause for 20 seconds)\n","\n","Calculating the above multiplication:\n","\n","\\[\n","\\text{Discount Amount} = 250 \\times 0.20 = 50\n","\\]\n","\n","### Step 2: Subtract the Discount from the Original Price\n","Now, we take the discount we just calculated and subtract it from the original price to find the final price.\n","\n","\\[\n","\\text{Final Price} = \\text{Original Price} - \\text{Discount Amount}\n","\\]\n","\\[\n","\\text{Final Price} = 250 - 50\n","\\]\n","\n","### (Pause for 20 seconds)\n","\n","Now calculating the final price:\n","\n","\\[\n","\\text{Final Price} = 250 - 50 = 200\n","\\]\n","\n","### Result\n","The final price after applying the 20% discount is $200.\n"]}]},{"cell_type":"markdown","source":["**What to observe:**\n","- The model should break down the calculation into clear steps:\n","    1) Calculate the discount amount (20% of $250 = $50)\n","    2) Subtract discount from original price ($250 - $50 = $200)\n","\n","\n","- Each step is verifiable and transparent\n","- The reasoning process is more reliable than the direct answer approach\n","- Low temperature typically produces more consistent step formatting"],"metadata":{"id":"GJZ1AWCZq_EH"}},{"cell_type":"markdown","source":["**When to Use Chain-of-Thought Prompting**\n","- Use CoT for:\n","    - Mathematical calculations and word problems\n","    - Multi-step logical reasoning\n","    - Complex decision-making tasks\n","    - Situations where you need to verify the reasoning\n","    - Tasks where intermediate steps provide valuable insight\n","    - Instructional contexts (showing someone how to solve problems)\n","\n","- Don't use CoT for:\n","    - Simple factual recall (\"What is the capital of France?\")\n","    - Creative writing tasks\n","    - When you need concise, quick responses\n","    - When the reasoning process isn't important"],"metadata":{"id":"YryW5STDqsRh"}}]}